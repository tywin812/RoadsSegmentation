{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "data_df = pd.read_csv(\"./roads_dataset/metadata.csv\")\n",
    "\n",
    "train_df = data_df.loc[data_df['split'] == 'train']\n",
    "\n",
    "val_df = data_df.loc[data_df['split'] == 'val']\n",
    "\n",
    "test_df = data_df.loc[data_df['split'] == 'test']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b906970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadsDataset(Dataset):\n",
    "    def __init__(self, df, is_train=False):\n",
    "        self.df = df\n",
    "        self.is_train = is_train\n",
    "        if not is_train:\n",
    "            self.patches = []\n",
    "            for idx in range(len(self.df)):\n",
    "                for y in range(0, 1536-512+1, 512):\n",
    "                    for x in range(0, 1536-512+1, 512):\n",
    "                        self.patches.append((idx,x,y))\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.df)\n",
    "        else:\n",
    "            return len(self.patches)\n",
    "    \n",
    "    def get_transforms(self):\n",
    "        if self.is_train:\n",
    "            trans = A.Compose([\n",
    "                A.RandomCrop(512,512),\n",
    "                A.SquareSymmetry(p=0.5),\n",
    "                \n",
    "                A.OneOf([\n",
    "                    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "                    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.6),\n",
    "                    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "                    A.RandomGamma(gamma_limit=(80, 120), p=0.6),\n",
    "                    A.Sharpen(p=0.6)\n",
    "                ], p=0.7),\n",
    "                                 \n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(std_range=(0.1, 0.2), p=0.5),\n",
    "                    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.5),\n",
    "                    A.MultiplicativeNoise(multiplier=(0.9, 1.1), per_channel=True, p=0.5),\n",
    "                    A.SaltAndPepper(p=0.5)\n",
    "                ], p=0.3),\n",
    "                \n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "                \n",
    "                ToTensorV2()\n",
    "            ])\n",
    "            return trans\n",
    "        else:\n",
    "            trans = A.Compose([\n",
    "                A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "                \n",
    "                ToTensorV2()\n",
    "            ])\n",
    "            return trans\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.is_train:\n",
    "            img_path = self.df.iloc[index]['tiff_image_path']\n",
    "            mask_path = self.df.iloc[index]['tif_label_path']       \n",
    "            data_dir = './roads_dataset'\n",
    "            img_path = os.path.join(data_dir, img_path)\n",
    "            mask_path = os.path.join(data_dir, mask_path)\n",
    "\n",
    "            orig_image = cv2.imread(img_path)\n",
    "            orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "            orig_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            image = cv2.resize(orig_image, (1536,1536), interpolation=cv2.INTER_CUBIC)\n",
    "            mask = cv2.resize(orig_mask, (1536,1536), interpolation=cv2.INTER_NEAREST)\n",
    "            mask = (mask == 255).astype('float32')\n",
    "\n",
    "            trans = self.get_transforms()\n",
    "        else:\n",
    "            img_idx,x,y = self.patches[index]\n",
    "            \n",
    "            img_path = self.df.iloc[img_idx]['tiff_image_path']\n",
    "            mask_path = self.df.iloc[img_idx]['tif_label_path']       \n",
    "            data_dir = './roads_dataset'\n",
    "            img_path = os.path.join(data_dir, img_path)\n",
    "            mask_path = os.path.join(data_dir, mask_path)\n",
    "\n",
    "            orig_image = cv2.imread(img_path)\n",
    "            orig_image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "            orig_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            image = cv2.resize(orig_image, (1536,1536), interpolation=cv2.INTER_CUBIC)\n",
    "            mask = cv2.resize(orig_mask, (1536,1536), interpolation=cv2.INTER_NEAREST)\n",
    "            mask = (mask == 255).astype('float32')\n",
    "\n",
    "            image = image[x:x+512, y:y+512, :]\n",
    "            mask = mask[x:x+512, y:y+512]\n",
    "            \n",
    "            trans = self.get_transforms()\n",
    "            \n",
    "        augmented = trans(image=image,mask=mask)\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask'].unsqueeze(0)\n",
    "        \n",
    "        return image,mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_ds, val_ds, device, num_epochs=200, batch_size=16, lr=1e-3, save_path='roads_seg.pth'):\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True, persistent_workers=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=8,pin_memory=True, persistent_workers=True)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {\"params\": model.encoder.layer1.parameters(), \"lr\": lr * 0.1},\n",
    "        {\"params\": model.encoder.layer2.parameters(), \"lr\": lr * 0.1},\n",
    "        {\"params\": model.encoder.layer3.parameters(), \"lr\": lr * 0.3},\n",
    "        {\"params\": model.encoder.layer4.parameters(), \"lr\": lr * 0.5},\n",
    "        {\"params\": model.decoder.parameters(), \"lr\": lr},\n",
    "    ], lr=lr)     \n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    train_losses, val_losses, val_ious = [], [], []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        train_bar = tqdm(train_loader, desc=f\"[Epoch {epoch}] Training\")\n",
    "        for imgs, labels in train_bar:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_iou, count = 0, 0, 0\n",
    "        val_bar = tqdm(val_loader, desc=f\"[Epoch {epoch}] Validation\")\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_bar:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                pred_masks = (probs > 0.5).float()\n",
    "                for pred, target in zip(pred_masks, labels):\n",
    "                    intersection = torch.logical_and(pred, target).sum().item()\n",
    "                    union = torch.logical_or(pred, target).sum().item()\n",
    "                    if union > 0:\n",
    "                        val_iou += intersection / union\n",
    "                        count += 1\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_iou = val_iou / count if count > 0 else 0\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_ious.append(avg_val_iou)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs} — Train Loss: {avg_train_loss:.4f} — Val Loss: {avg_val_loss:.4f} — Val IoU: {avg_val_iou:.2f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Saved new best model at epoch {epoch}\")\n",
    "\n",
    "    return train_losses, val_losses, val_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", classes=1)\n",
    "train_dataset = RoadsDataset(train_df, is_train=True)\n",
    "val_dataset = RoadsDataset(val_df, is_train=False)\n",
    "\n",
    "train_losses, val_losses, val_ious = train(model, train_dataset, val_dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ba254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one_image(model, dataset, img_idx):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        full_pred = torch.zeros((1536, 1536), dtype=torch.float32).to(device)\n",
    "\n",
    "        for idx, (patch_idx, y, x) in enumerate(dataset.patches):\n",
    "            if patch_idx != img_idx:\n",
    "                continue  \n",
    "\n",
    "            image, _ = dataset[idx] \n",
    "            image = image.unsqueeze(0).to(device) \n",
    "\n",
    "            pred = model(image)  \n",
    "            pred = torch.sigmoid(pred)\n",
    "            pred = (pred>0.5).float()\n",
    "            pred = pred.squeeze(0).squeeze(0) \n",
    "\n",
    "            full_pred[y:y+512, x:x+512] += pred\n",
    "\n",
    "        return full_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RoadsDataset(df=test_df, is_train=False)\n",
    "model = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", classes=1)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('roads_seg.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "ious = []\n",
    "for i in range(len(test_df)):\n",
    "    full_pred = inference_one_image(model,test_dataset,i)\n",
    "    \n",
    "    mask_path = test_df.iloc[i]['tif_label_path']       \n",
    "    data_dir = './roads_dataset'\n",
    "    mask_path = os.path.join(data_dir, mask_path)\n",
    "    true_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    true_mask = (true_mask == 255).astype('float32')\n",
    "    true_mask = cv2.resize(true_mask, (1536,1536), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    intersection = np.logical_and(full_pred, true_mask).sum()\n",
    "    union = np.logical_or(full_pred, true_mask).sum()\n",
    "    \n",
    "    iou = intersection/union\n",
    "    ious.append(iou)\n",
    "\n",
    "print(f\"Test IoU: {np.mean(ious)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
